{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import config as cf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pandas.io.json import json_normalize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "# from collections import OrderedDict\n",
    "from nltk import word_tokenize\n",
    "import math\n",
    "from odict import odict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    try:\n",
    "        return math.log(x)\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notEnglish(s): \n",
    "    results = []\n",
    "    for t in s:\n",
    "        try:\n",
    "            t.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            results.append(True)\n",
    "        else:\n",
    "            results.append(False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = cf.ROOT_PATH + cf.DATA_PATH\n",
    "reviewPath = dataPath + 'review.json'\n",
    "max_records = 1e5\n",
    "df = pd.read_json(reviewPath, lines=True, chunksize=max_records)\n",
    "reviews = pd.DataFrame() # Initialize the dataframe\n",
    "print('next step')\n",
    "i = 0\n",
    "try:\n",
    "   for df_chunk in tqdm(df):\n",
    "       if i > 2:\n",
    "            break\n",
    "       reviews = pd.concat([reviews, df_chunk])\n",
    "       print(i)\n",
    "       i=i +1\n",
    "except ValueError:\n",
    "       print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(reviews[notEnglish(reviews['text'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(dataPath + 'user.json', lines=True, chunksize=max_records)\n",
    "users = pd.DataFrame() # Initialize the dataframe\n",
    "print('next step')\n",
    "i = 0\n",
    "try:\n",
    "   for df_chunk in tqdm(df):\n",
    "       if i > 2:\n",
    "            break\n",
    "       users = pd.concat([users, df_chunk])\n",
    "       print(i)\n",
    "       i=i +1\n",
    "except ValueError:\n",
    "       print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.merge(users[['user_id', 'cool', 'useful', 'funny', 'fans', 'review_count']], left_on='user_id', right_on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['user_score'] = 0\n",
    "reviews['user_score'] = ((reviews['useful_y'].apply(log) + reviews['funny_y'].apply(log) + reviews['cool_y'].apply(log) + reviews['fans'].apply(log))/reviews['review_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review_score'] = 0\n",
    "reviews['review_score'] = reviews['useful_x'].apply(log) + reviews['cool_x'].apply(log) + reviews['funny_x'].apply(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(reviews[(reviews['user_score'] == 0) & (reviews['review_score'] == 0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = ['food', 'price', 'service', 'ambience', 'misc']\n",
    "for aspect in aspects:\n",
    "    reviews[aspect] = random.uniform(reviews['stars'], reviews['stars'] * 9/4 - 29/4) * (reviews['review_score'] + reviews['user_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['date', 'useful_x', 'funny_x', 'cool_x', 'useful_y', 'cool_y', 'funny_y', 'user_id', 'fans', 'review_count', 'user_score', 'review_score']\n",
    "reviews = reviews.drop(drop_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['AZ', 'NC', 'NV', 'IL', 'OH', 'PA', 'WI']\n",
    "i = 0\n",
    "for state in states:\n",
    "        statePath = dataPath + 'business_consumer/' + state\n",
    "        for subdir, _, files in tqdm(os.walk(statePath)):\n",
    "            for file in files:\n",
    "                if 'business-ids.json' not in file:\n",
    "                    business = pd.read_json(os.path.join(statePath, file))\n",
    "                    leftcols = ['business_id', 'text', 'food', 'price', 'service', 'ambience', 'misc']\n",
    "                    business = business.merge(reviews[leftcols], left_on='business_id', right_on='business_id') \n",
    "                    business.to_json(dataPath + '%s_business.json' % state, orient= 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=set(stopwords.words('english'))\n",
    "for state in states:\n",
    "    stateBusiness = dataPath + '%s_business.json' % state\n",
    "    business = pd.read_json(stateBusiness)\n",
    "    business['text'] = [dict(Counter(list(filter(lambda w: not w in s and w.isalpha(),word_tokenize(txt.lower()))))) for txt in tqdm(business['text'])]\n",
    "    business.to_json(dataPath + '%s_business.json' % state, orient= 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = cf.ROOT_PATH + cf.DATA_PATH\n",
    "file = dataPath + 'Tempe_business_processed.json'\n",
    "business = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonCols = ['address', 'business_id', 'city', 'latitude', 'longitude', 'name', 'postal_code', 'review_count', 'stars_x', 'state']\n",
    "dictCols = ['business_id', 'text', 'hours', 'categories', 'stars_y']\n",
    "dropCols = ['attributes', 'is_open', 'text', 'hours', 'categories', 'stars_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced = business[dictCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = business.drop(dropCols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sliced[['business_id', 'text', 'stars_y']]\n",
    "sliced = sliced.drop('text', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = dropped.groupby(commonCols).sum()\n",
    "dropped = dropped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodText = text[text['stars_y'] >= 4.0]\n",
    "badText = text[text['stars_y'] <= 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allId = text['business_id']\n",
    "badId = badText['business_id']\n",
    "goodId = goodText['business_id']\n",
    "between = text[(text['stars_y'] < 4.0) & (text['stars_y'] > 2.0)]\n",
    "beId = between['business_id']\n",
    "dropIds = beId[~beId.isin(goodId.append(badId))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped=dropped[~dropped['business_id'].isin(dropIds)]\n",
    "text = text[~text['business_id'].isin(dropIds)]\n",
    "sliced = sliced[~sliced['business_id'].isin(dropIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stars\n",
    "stars = text.groupby(['business_id', 'stars_y'])['stars_y'].size().unstack(fill_value=0)\n",
    "stars = stars.reset_index()\n",
    "stars[[1,2,3,4,5]] = stars[[1,2,3,4,5]].divide(stars.sum(1), 0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(df):\n",
    "    return dict(sum((Counter(dict(x)) for x in df['text']), Counter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderDict(x):\n",
    "    d = odict(sorted(x.items(), key=lambda t: t[1], reverse=True))\n",
    "    results = {}\n",
    "    i = 0\n",
    "    for key, value in d.items():\n",
    "        if i > 19:\n",
    "            break\n",
    "        results[key] = value\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodText = goodText.groupby('business_id').apply(counter).reset_index()\n",
    "badText = badText.groupby('business_id').apply(counter).reset_index()\n",
    "goodText[0] = goodText[0].apply(orderDict)\n",
    "badText[0] = badText[0].apply(orderDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced = sliced.groupby('business_id').last().reset_index()\n",
    "sliced = sliced.drop('stars_y',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything together\n",
    "temp = pd.concat([sliced, goodText])\n",
    "temp = temp.groupby('business_id').last().reset_index()\n",
    "temp = temp.rename(index=str, columns={0: \"good words\"})\n",
    "temp = pd.concat([temp, badText])\n",
    "temp = temp.groupby('business_id').last().reset_index()\n",
    "temp = temp.rename(index=str, columns={0: \"bad words\"})\n",
    "temp = pd.concat([temp, stars]).groupby('business_id').last().reset_index()\n",
    "temp = pd.concat([dropped, temp]).groupby('business_id').last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_json(dataPath + 'test.json', orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([test, testBad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodText[0] = goodText[0].apply(orderDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = odict(sorted(goodText[0][0].items(), key=lambda t: t[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {}\n",
    "i = 0\n",
    "for key, value in a.items():\n",
    "    if i > 19:\n",
    "        break\n",
    "    test[key] = value\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodText[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
